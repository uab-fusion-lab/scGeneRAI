{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31000a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import scGeneRAI\n",
    "import os\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c57f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex_data = pd.read_csv('../scGeneRAI/data/example_data.csv').iloc[:,3:]\n",
    "# ex_data_descriptors = pd.read_csv('../scGeneRAI/data/example_data.csv').iloc[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw = pd.read_csv('../scGeneRAI/data/raw_data.csv')\n",
    "filtered_raw = raw[ raw['Cell.Type'].str.count(',') == 0]\n",
    "filtered_raw = filtered_raw[filtered_raw['Cell.Type'] != 'Unknown']\n",
    "ex_data = filtered_raw.iloc[:,13:]\n",
    "ex_data_descriptors = filtered_raw.iloc[:,[2,12]]\n",
    "data = pd.concat([ex_data_descriptors, ex_data], axis=1)\n",
    "# column_names = data.columns.tolist()\n",
    "# column_names[0]\n",
    "df_sorted = data.sort_values(by=['Cell.Type', 'orig.ident'])\n",
    "df_sorted.to_csv('./data/sorted_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "      orig.ident  Cell.Type\n0        Control  Columella\n1        Control  Columella\n2        Control  Columella\n3        Control  Columella\n4        Control  Columella\n...          ...        ...\n11527     DC3000      Xylem\n11528     DC3000      Xylem\n11529     DC3000      Xylem\n11530     DC3000      Xylem\n11531     DC3000      Xylem\n\n[11532 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>orig.ident</th>\n      <th>Cell.Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Control</td>\n      <td>Columella</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Control</td>\n      <td>Columella</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Control</td>\n      <td>Columella</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Control</td>\n      <td>Columella</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Control</td>\n      <td>Columella</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11527</th>\n      <td>DC3000</td>\n      <td>Xylem</td>\n    </tr>\n    <tr>\n      <th>11528</th>\n      <td>DC3000</td>\n      <td>Xylem</td>\n    </tr>\n    <tr>\n      <th>11529</th>\n      <td>DC3000</td>\n      <td>Xylem</td>\n    </tr>\n    <tr>\n      <th>11530</th>\n      <td>DC3000</td>\n      <td>Xylem</td>\n    </tr>\n    <tr>\n      <th>11531</th>\n      <td>DC3000</td>\n      <td>Xylem</td>\n    </tr>\n  </tbody>\n</table>\n<p>11532 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv('../scGeneRAI/data/sorted_data.csv')\n",
    "ex_data = raw.iloc[:,2:]\n",
    "ex_data_descriptors = raw.iloc[:,:2]\n",
    "ex_data_descriptors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "means = ex_data.mean(axis=0)\n",
    "sds = ex_data.std(axis=0)\n",
    "\n",
    "ex_data = (ex_data-means)/sds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ex_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ex_data_descriptors.iloc[:61,:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(ex_data_descriptors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ex_data_descriptors.iloc[61:984,:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9ac6827",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = scGeneRAI.scGeneRAI(ex_data, model_depth =2, descriptors = ex_data_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e291798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:14<00:00, 14.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the network trained for 5 epochs (testloss: 1.0691689252853394)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(ex_data, nepochs = 5, model_depth =2, descriptors = ex_data_descriptors, early_stopping=False, device_name = torch.device('cuda'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "torch.save(model.nn.state_dict(), 'saved_model.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.nn.load_state_dict(torch.load('saved_model.pt'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea26159a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m preds \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict_networks(ex_data\u001B[38;5;241m.\u001B[39miloc[:\u001B[38;5;241m61\u001B[39m,:], descriptors \u001B[38;5;241m=\u001B[39m ex_data_descriptors\u001B[38;5;241m.\u001B[39miloc[:\u001B[38;5;241m61\u001B[39m,:], PATH \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m, device_name \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "File \u001B[1;32mD:\\PycharmProjects\\scGeneRAI\\scGeneRAI.py:253\u001B[0m, in \u001B[0;36mscGeneRAI.predict_networks\u001B[1;34m(self, data, descriptors, LRPau, remove_descriptors, device_name, PATH)\u001B[0m\n\u001B[0;32m    251\u001B[0m \u001B[38;5;28mprint\u001B[39m(sample_id)\n\u001B[0;32m    252\u001B[0m path \u001B[38;5;241m=\u001B[39m calc_all_paths(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnn, data_tensor_LRP, sample_id, sample_name, feature_names_LRP, target_gene_range \u001B[38;5;241m=\u001B[39m target_gene_range, PATH\u001B[38;5;241m=\u001B[39mPATH, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, LRPau \u001B[38;5;241m=\u001B[39m LRPau, device \u001B[38;5;241m=\u001B[39m tc\u001B[38;5;241m.\u001B[39mdevice(device_name))\n\u001B[1;32m--> 253\u001B[0m network_data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([result, path])\n\u001B[0;32m    254\u001B[0m network_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLRP\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mabs(network_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLRP\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m    255\u001B[0m network_data \u001B[38;5;241m=\u001B[39m network_data[network_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msource_gene\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m!=\u001B[39m network_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget_gene\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.3.3\\plugins\\python\\helpers\\pydev\\_pydevd_bundle\\pydevd_frame.py:747\u001B[0m, in \u001B[0;36mPyDBFrame.trace_dispatch\u001B[1;34m(self, frame, event, arg)\u001B[0m\n\u001B[0;32m    745\u001B[0m \u001B[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001B[39;00m\n\u001B[0;32m    746\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info\u001B[38;5;241m.\u001B[39mpydev_state \u001B[38;5;241m==\u001B[39m STATE_SUSPEND:\n\u001B[1;32m--> 747\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdo_wait_suspend(thread, frame, event, arg)\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;66;03m# No need to reset frame.f_trace to keep the same trace function.\u001B[39;00m\n\u001B[0;32m    749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrace_dispatch\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.3.3\\plugins\\python\\helpers\\pydev\\_pydevd_bundle\\pydevd_frame.py:144\u001B[0m, in \u001B[0;36mPyDBFrame.do_wait_suspend\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 144\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_args[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdo_wait_suspend(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.3.3\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.3.3\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "preds = model.predict_networks(ex_data.iloc[:61,:], descriptors = ex_data_descriptors.iloc[:61,:], PATH = '.', device_name = torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e121e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_data = pd.concat(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33925ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('./results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf5be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_data = pd.concat([pd.read_csv('./results/' + file) for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c790e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_data['LRP'] = np.abs(network_data['LRP'])\n",
    "network_data = network_data[network_data['source_gene'] != network_data['target_gene']]\n",
    "\n",
    "average_network = network_data[['LRP', 'source_gene', 'target_gene']].groupby(['source_gene', 'target_gene']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9fc8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = preds.sort_values(by='LRP', ascending=False)#.iloc[:200,:]\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d905dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = nx.from_pandas_edgelist(edges, source='source_gene', target='target_gene', edge_attr='LRP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(network, with_labels=False, node_size=0, node_color='white', width = edges['LRP']*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d098a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_networks(ex_data.iloc[61:984,:], descriptors = ex_data_descriptors.iloc[61:984,:], PATH = '.', device_name = torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network_data = pd.concat([preds1, preds])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_network = network_data[['LRP', 'source_gene', 'target_gene']].groupby(['source_gene', 'target_gene']).sum().reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_network['LRP'] = final_network['LRP'] / 923\n",
    "final_network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edges = final_network.sort_values(by='LRP', ascending=False)#.iloc[:200,:]\n",
    "edges"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed85b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = nx.from_pandas_edgelist(edges, source='source_gene', target='target_gene', edge_attr='LRP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nx.draw(network, with_labels=False, node_size=0, node_color='white', width = edges['LRP']*0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(ex_data_descriptors.iloc[984:1148,:])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = scGeneRAI.scGeneRAI(ex_data, model_depth =2, descriptors = ex_data_descriptors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.nn = torch.load('saved_model.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds1 = model.predict_networks(ex_data.iloc[:61,:], descriptors = ex_data_descriptors.iloc[:61,:], PATH = '.', device_name = torch.device('cuda'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
